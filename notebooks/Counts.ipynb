{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurence of Term Analysis\n",
    "\n",
    "Co-occurence of terms analysis: check how often pre-selected cognitive terms appear in abstracts with ERP terms. \n",
    "\n",
    "This analysis searches through pubmed for papers that contain specified ERP and COG terms. Data extracted is the count of the number of papers with both terms. This is used to infer what cognitive terms each ERP is affiliated with. \n",
    "\n",
    "NOTE:\n",
    "- COG terms here are a somewhat arbitrary selection: need a better set of terms, less arbitrarily selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('/Users/thomasdonoghue/Documents/GitCode/ERP_SCANR/')\n",
    "\n",
    "# Import custom code\n",
    "from erpsc.count import Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize object for term count co-occurences. \n",
    "counts = Count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load ERPS and terms from file\n",
    "counts.set_erps_file()\n",
    "counts.set_terms_file('cognitive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unloading previous ERP words.\n",
      "Unloading previous terms words.\n"
     ]
    }
   ],
   "source": [
    "# OR: Set small set of ERPs and terms for tests\n",
    "\n",
    "# Small test set of words\n",
    "erps = ['N400', 'P600']\n",
    "cog_terms = ['language', 'memory'] \n",
    "\n",
    "# Add ERPs and terms\n",
    "counts.set_erps(erps)\n",
    "counts.set_terms(cog_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasdonoghue/anaconda/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Scrape the co-occurence of terms data\n",
    "counts.scrape_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the  N400  the most common association is \t ['language'] with \t %45.50\n",
      "For the  P600  the most common association is \t ['language'] with \t %58.83\n"
     ]
    }
   ],
   "source": [
    "# Check the most commonly associated COG term for each ERP\n",
    "counts.check_cooc_erps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  ['language']         the strongest associated ERP is \t P600  with \t %58.83\n",
      "For  ['memory']           the strongest associated ERP is \t N400  with \t %21.94\n"
     ]
    }
   ],
   "source": [
    "# Check the most commonly associated ERP for each term\n",
    "counts.check_cooc_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most studied ERP is  ['N400']  with     1901 papers\n",
      "The most studied term is  ['memory']  with   224064  papers\n"
     ]
    }
   ],
   "source": [
    "# Check the terms with the most papers\n",
    "counts.check_top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N400  -     1901\n",
      "P600  -      549\n"
     ]
    }
   ],
   "source": [
    "# Check how many papers were found for each term - ERPs\n",
    "counts.check_counts('erp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['language']       -     145436\n",
      "['memory']         -     224064\n"
     ]
    }
   ],
   "source": [
    "# Check how many papers were found for each term - COGs\n",
    "counts.check_counts('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save pickle file of results\n",
    "counts.save_pickle('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load from pickle file\n",
    "counts = load_pickle_counts('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate_from_frequencies(words_analysis.results[0].freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(words_analysis.results[0].freqs)\n",
    "\n",
    "words_analysis.results[0].freqs.plot(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_analysis.results[0].freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEST IMPORTS\n",
    "#import requests\n",
    "#import nltk\n",
    "#from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "page = requests.get('http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&field=word&term=“N270”AND”Language”')\n",
    "#page = requests.get('http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&field=word&term=“P300”&retmax=10')\n",
    "#page = requests.get('http://www.ncbi.nlm.nih.gov/pubmed/27354714')\n",
    "\n",
    "page_soup = BeautifulSoup(page.content)\n",
    "\n",
    "#counts = page_soup.find_all('count')\n",
    "\n",
    "#for i in range(0, len(counts)):\n",
    "#    count = counts[i]\n",
    "#    ext = count.text\n",
    "#    print int(ext)\n",
    "\n",
    "#art_page = requests.get('http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&id=' + id_strs)\n",
    "\n",
    "#art_page_soup = BeautifulSoup(art_page.content, \"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = page_soup.find_all('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
